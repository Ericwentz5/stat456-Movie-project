---
title: "Decoding Cult Classics: What Separates the Films That Stick?"
author: "Eric Wentz, Natalia Morales Flores, Sebastian Stefonowicz"
format: html
editor: visual
---

```{r}
#| echo: false
#| message: false
library(tidyverse)
library(ggplot2)
library(lubridate)
library(bslib)
library(dplyr)
library(tidyr)
library(tibble)
library(stringr)
```

In a time when data science is often used to tackle heavy societal issues like healthcare, economics, climate, and inequality, we decided to take a different route. We wanted to remind ourselves that creativity and curiosity also have a place in analytics. We chose movies, a fun and creative domain, and approached them with a serious analytical mindset. Movies are inherently unquantifiable. Their interpretations are subjective, emotionally driven, and culturally dependent. To us, this is exactly what makes the challenge interesting. The differences in our project were not only in the questions we asked but also in the type of data we worked with. Our datasets involved messy concepts such as cult status, genre identity, and fandom behavior, which are very different from typical structured and numerical data. Our project sits at the intersection of AI, culture, and entertainment analytics. We followed standard data science practices such as data collection, cleaning, and visualization, and combined them with large language model based labeling to analyze a concept that does not naturally exist in structured form.
<br>
<br>
Cult classics are films with particularly dedicated fanbases and cultural staying power. Throughout the semester, we aimed to determine first, if there are measurable characteristics that distinguish cult classics from other films, and secondly, whether or not we can measure them. This question is significant because existing scholarship on cult cinema largely emphasizes qualitative dimensions such as transgression, niche audiences, and subcultural identity, while offering limited quantitative analysis of film attributes (see Mathijs and Mendik, The Cult Film Reader). Since it did not previously exist, our first step was to create a cult status indicator variable with the assistance of generative AI, that would be the basis for our empirical investigation. The next phase of our project employed traditional data science methods to explore trends in thematic key words, genres, and popularity over time for cult and non-cult films. The last phase, rather ambitiously, implemented statistical machine learning tools to model and attempt to predict future cult status for recent films.

## Data

We work with two main preexisting data sources: The Movie Database (TMDb) and the Internet Movie Database (IMDb). Our TMDb dataset contains one row per movie for the 10,000 highest rated films by TMDb user score and includes fields such as title, release date, budget, revenue, average vote, etc. We also attach an LLM-generated binary label (cult = 1/0) derived from a prompt-based cult score and a chosen threshold. Cleaning for TMDb focuses on standardizing identifiers and dates, removing duplicates, handling implicit missingness, and normalizing text fields, so titles match consistently across sources.
<br>
<br>
IMDb provides two types of information that TMDb does not, audience activity over time and credit metadata. For ratings activity, we use an IMDb table for votes over time with fields like ID number, year, number of ratings, and a timestamp for each vote. This data powers our time series curves and the derived cult trajectory metrics. Cleaning on the IMDb side includes filtering to titles that appear in our TMDb list, coercing years to numeric, removing implausible years, aggregating multiple vote records to a single ID and year count when needed, and ensuring consistent ID formats. Finally, we join by matching cleaned titles and release years, then carry the IMDb/TMDb IDs forward so all downstream modeling and visualizations use a single consistent movie identifier.
<br>
<br>
As touched on in the introduction, there is not an indicator of cult status in any publicly available data. Since our goal was to explore and model characteristics of cult films, we needed a dependent variable. To remedy this we used the OpenAI API to feed chatgpt-4.1-mini the title and release date of all films in our dataset released before 2010 and asked for the structured output of a cult 1/0 indicator variable. To stabilize the variability inherent in generative AI responses, we ran the query five times with the same prompt, and selected films identified as cult classics in at least four out of five queries as what we would consider cult films.

```{r}
#| echo: false
movies_w_index <- read.csv("./data/10k_pre-2010-01-01-w-llm-classification.csv")

ratings_df <- read.csv("~/Documents/COMP 456/FP4/ml-32m/ratings.csv")
#ratings_df <- read.csv("./data/ratings.csv")

movies_df <- read.csv("./data/movies.csv")

#movies_clean <- readRDS("~/Desktop/Mac_Code/STAT_456/stat456-Movie-project/data/movies_clean.rds")

```

## Processes and outcomes

Our main question, “what makes a movie a cult classic?”, ended up being less about a single “secret ingredient” and more about a handful of measurable signals that often come together: what the movie is like, who it seems made for, and how audiences find it over time. Across the results, the strongest pattern is that cult status tends to emerge when a film is distinctive enough to attract a specific audience, and that audience has reasons to keep returning to it and recommending it.
<br>
<br>
Two descriptive visuals capture the content signature of cult films: the genre-proportion heatmap and the top keywords bar chart. In the heatmap, the cult-column is visibly darker for Horror, Thriller, and Comedy, while the non-cult absence column is dominated by Drama, a more mainstream “default” genre bucket. The very slight presence of Animation, Family, and War among cult classics is also notable, suggesting that in this dataset cult status rarely forms around films that are either aimed at a broader audience or tied to conventional prestige or historical framing. While genre alone does not define cult status, there is certainly correlation.

```{r}
#| echo: false


# genre_cult_heatmap <- movies_clean %>%
#   unnest(genres_list) %>%
#   count(cult_classic, genres_list) %>%
#   group_by(cult_classic) %>%
#   mutate(prop = n / sum(n)) %>%
#   mutate(cult_classic = ifelse(cult_classic == 1, "Cult", "Not Cult"))
# 
# ggplot(genre_cult_heatmap, aes(x = cult_classic, y = genres_list, fill = prop)) +
#   geom_tile(color = "white") +
#   scale_fill_gradient(low = "white", high = "red") +
#   labs(title = "Genre Proportions: Cult vs. Non-Cult Classics",
#        x = "Movie Type", y = "Genre", fill = "Proportion") +
#   theme_minimal(base_size = 14)
# 
# top_cult_keywords <- movies_clean %>%
#   filter(cult_classic == 1) %>%
#   unnest(keywords_list) %>%
#   count(keywords_list, sort = TRUE) %>%
#   slice_max(n, n = 25)
# 
# ggplot(top_cult_keywords, aes(
#   x = reorder(keywords_list, n), y = n, fill = n
# )) +
#   geom_col() +
#   coord_flip() +
#   scale_fill_gradient(low = "skyblue", high = "darkblue") +
#   theme_minimal() +
#   labs(
#     title = "Top 25 Keywords Among Cult Classics",
#     x = "Keyword",
#     y = "Count"
#   )
# 

```

The keyword chart shows how cult films differ within or alongside genres. The most common keywords cluster around dark, transgressive, or subcultural themes. Importantly, some keywords aren’t just themes, they are signals of style and structure, like a stinger during or after credits, which point to films that reward insider viewing habits. The broader trend here is that cult classics aren’t just “good movies people like”, but they are often movies with strong identity markers that make it easy for fans to rally around and recommend to other fans.
<br>
<br>
These visuals also imply why cult status can feel intangible. Our measured features capture what is on screen, but cult status also depends on social transmission, viewing rituals, and timing.
<br>
<br>
The Shiny app lets us treat “cultness” as something you can see in the shape of audience attention over time, not just in a genre label. For any selected movie, it plots ratings activity by year and overlays a smoothed curve, then summarizes that curve with four interpretable metrics: Time-to-takeoff (T₅₀), the number of years it takes to reach 50% of lifetime ratings; peak-lag, the time from release to the highest point of attention; a long-tail ratio comparing ratings in years 5–15 to ratings in years 0–2; and decay half-life, how quickly attention falls after the peak. Together, these metrics reveal at least two common “pathways” a film can take. Some titles look like slow-burn / rediscovery cases: they reach T₅₀ late, peak years after release, and have long-tail ratios above 1, meaning a substantial portion of attention arrives well after the initial release window—consistent with word-of-mouth spread, rewatching, streaming-era rediscovery, or fandom growth over time. In the Pride & Prejudice (2005) example shown, the pattern is strongly late-life: T₅₀ = 11 years, peak-lag = 11 years, and a long-tail ratio ≈ 4.14, indicating that far more engagement happens years later than in the first two years. Other movies show the opposite mainstream spike profile: low T₅₀ and short peak-lag, with attention concentrated near release and then fading relatively quickly, which matches films that are heavily consumed during their initial marketing/theatrical moment. This time-horizon framing helps us move beyond “cult is a vibe” and toward measurable subtypes: even without explicitly modeling director reputation, the curves point to different mechanisms of visibility—launch-driven attention versus delayed, community-driven accumulation—that map closely onto how cult followings tend to form.
<br>

> The Shiny app is included as an external qmd located in the same folder as this file in the Github repository.

These two plots scale up the Shiny-app idea from single movies to the whole dataset by summarizing the typical ratings trajectory for cult vs. non-cult films.
<br>
<br>
In the first figure, we align every movie by years since release and convert yearly rating counts into the share of that film’s lifetime ratings, so the comparison is about shape and timing rather than raw popularity. The result is a clear split: non-cult films are more front-loaded, with a sharp spike in the first 1–2 years and then a gradual decline, consistent with mainstream release cycles and early mass attention. Cult classics, in contrast, show a smaller initial spike but relatively higher activity later, especially in the mid-life window (roughly years 5–15) and a subtle late lift, suggesting a longer “afterlife” driven by rediscovery, niche communities, and repeated recommendation rather than a single launch moment.

```{r}
#| echo: false
#| warning: false
# Ratings with timestamps
ratings_clean <- ratings_df %>%
  transmute(
    movieId = as.character(movieId),
    ts_num  = suppressWarnings(as.numeric(timestamp)),
    ts_num  = if_else(!is.na(ts_num) & ts_num > 1e12, ts_num/1000, ts_num), # ms→s
    ts      = as_datetime(ts_num, tz = "UTC")
  ) %>% filter(!is.na(ts))

# Titles, extracts release year and a normalized title key
titles_clean <- movies_df %>%
  transmute(
    movieId     = as.character(movieId),
    title_raw   = as.character(title),
    release_year = str_extract(title_raw, "\\d{4}(?=\\)\\s*$)") %>% as.integer(),
    title_lower = str_to_lower(title_raw),
    title_no_yr = str_remove(title_lower, "\\s*\\(\\d{4}\\)\\s*$"),
    title_norm  = str_squish(str_replace_all(title_no_yr, "[^a-z0-9]+", " "))
  )

# Cult labels joined by normalized title
index_clean <- movies_w_index %>%
  transmute(
    title_idx_raw   = as.character(title),
    title_idx_lower = str_to_lower(title_idx_raw),
    title_idx_no_yr = str_remove(title_idx_lower, "\\s*\\(\\d{4}\\)\\s*$"),
    title_norm      = str_squish(str_replace_all(title_idx_no_yr, "[^a-z0-9]+", " ")),
    llm_class_final = as.integer(llm_class_final),
    class = if_else(llm_class_final == 1, "Cult classic", "Non-cult")
  )

# Labeled events
labeled <- ratings_clean %>%
  left_join(titles_clean, by = "movieId") %>%
  left_join(index_clean,  by = "title_norm") %>%
  filter(!is.na(class)) %>%
  group_by(movieId) %>%
  mutate(release_year = if_else(is.na(release_year), min(year(ts), na.rm = TRUE), release_year)) %>%   #if a title had no year, use first observed rating year
  ungroup() %>%
  mutate(rating_year = year(ts),
         age = rating_year - release_year) %>%
  filter(!is.na(age), age >= 0, age <= 20)  # cap at 20 years for a clean window

# yearly counts per film → shares
age_counts <- labeled %>%
  count(movieId, class, age, name = "n")

film_totals <- age_counts %>%
  group_by(movieId) %>% summarise(total_n = sum(n), .groups = "drop")

age_share <- age_counts %>%
  left_join(film_totals, by = "movieId") %>%
  mutate(share = n / total_n)

# Average curves across films by class
curve_share <- age_share %>%
  group_by(class, age) %>%
  summarise(mean_share = mean(share, na.rm = TRUE), .groups = "drop")

# Cumulative version + median T50 per class
curve_cum <- age_share %>%
  group_by(movieId, class) %>%
  arrange(age, .by_group = TRUE) %>%
  mutate(cum_share = cumsum(share)) %>%
  ungroup() %>%
  group_by(class, age) %>%
  summarise(mean_cum_share = mean(cum_share, na.rm = TRUE), .groups = "drop")

t50_by_film <- age_share %>%
  group_by(movieId, class) %>%
  arrange(age, .by_group = TRUE) %>%
  mutate(cum_share = cumsum(share)) %>%
  summarise(T50 = age[which(cum_share >= 0.5)[1]], .groups = "drop")

t50_median <- t50_by_film %>%
  group_by(class) %>%
  summarise(median_T50 = median(T50, na.rm = TRUE), .groups = "drop")
```

```{r}
#| echo: false

p1 <- ggplot(curve_share, aes(age, mean_share, color = class)) +
  geom_line(linewidth = 1) +
  #geom_smooth(se = FALSE, method = "loess", span = 0.5, linewidth = 0.8) +
  labs(title = "Typical ratings pattern by years since release",
       x = "Years since release", y = "Average share of a film's lifetime ratings",
       color = NULL) +
  theme_minimal(base_size = 13) + theme(legend.position = "top")

print(p1)
```

The second figure makes that timing difference even easier to interpret by tracking how quickly ratings accumulate over a film’s life. The dashed vertical lines mark T50, the time it takes the average film to reach 50% of its lifetime ratings. Here, the non-cult curve reaches the halfway point earlier, while the cult curve hits T50 later, meaning cult attention builds more gradually over time. Together, these visuals reinforce the central pattern behind our curve metrics: cult classics are less dominated by early release period attention and more defined by a long tail / slow-burn accumulation, which matches what the Shiny app shows at the individual movie level, just averaged across thousands of titles. Because everything is expressed in shares and within a capped 0–20 year window, the takeaway is explicitly about relative timing, not absolute “how popular” a movie is.

```{r}
#| echo: false

p2 <- ggplot(curve_cum, aes(age, mean_cum_share, color = class)) +
  geom_line(linewidth = 1) +
  labs(title = "Average cumulative share (T50 marked)",
       x = "Years since release", y = "Average cumulative share",
       color = NULL) +
  geom_vline(data = t50_median, aes(xintercept = median_T50, color = class),
             linetype = "dashed", linewidth = 0.8, show.legend = FALSE) +
  theme_minimal(base_size = 13) + theme(legend.position = "top")

print(p2)
```

So what makes a cult classic based on these results? A cult classic is most often a movie with strong identity cues, niche target appeal that makes it easy for fans to find community, and an attention curve that supports that community-building. The “recipe” is real in the sense that these signals cluster, but cult status stays partly intangible because it ultimately requires collective adoption over time, which is why our trajectory metrics and prediction work complement each other. They measure how cultness happens, not just what the film is.

## Limitations

A key limitation is that our “cult” outcome is only a placeholder for a social phenomenon that is partly cultural and community-driven. The LLM label (and therefore the model trained on it) may encode bias, especially toward horror or edgy keywords. And even after removing horror in one figure, the underlying signal can still privilege genres and tropes that sound cult-like rather than films that actually developed sustained fan communities. Similarly, our genre and keyword visuals summarize what’s common, but they don’t prove causation. Genres and themes correlate with cult status, yet they may just be markers of niche marketing or availability rather than the reason a fandom formed. The ratings trajectory app helps by introducing a time dimension, but it also has blind spots. Ratings volume reflects who is on the platform and when, and slow-burn could reflect streaming release timing, re-releases, awards, etc., not cult adoption per se. Finally, our visuals don’t directly measure the mechanisms people often associate with cult classics, such as public screening, quotability, online communities, controversy, or critical evaluation. So an open question is how much cult status is driven by social transmission and context versus the measurable content features we captured. These gaps point to next steps like validating labels against external lists, separating theatrical vs streaming eras, and adding signals for fandom activity to better distinguish true cult formation from general late popularity.

## Contributions

### Eric

Led the analysis of genre- and keyword-based features used to characterize cult classic films. He was responsible for cleaning and structuring the nested genre and keyword data, developing the genre and keyword proportion heatmaps, and ensuring these analyses were reproducible through properly saved and loaded processed datasets. In addition to his analytical contributions, Eric coordinated and scheduled meetings with the external domain expert, helped streamline communication among team members, and translated group discussions into concrete analytical steps. He also contributed to multiple sections of the written report, refining methodological descriptions and results narratives to improve clarity and coherence.

### Natalia

Led the analysis of ratings over time for individual movies and general patterns. Created shiny app with four different metrics to help identify if a movie is a slow-burn or mainstream, the first one being a better candidate to be considered a cult film. Created two plots to visualize patterns of movies classified as cults by Sebastian's LLM vs. non-cults in terms of number of ratings over time (years since release). Created lists and outlines for task delegation, set meeting times with Google Calendar, and contributed to the final screencast slides for research questions, data description, limitations and open questions. Organized Github for final submission, created and organized qmd for final narrative. Wrote data description, interpretations for the shiny app and ratings plots, and Limitations for the final narrative. 

### Sebastian
